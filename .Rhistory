#Proximity rasters in qgis
#Append per matching year:
#convert timestamp to year
clipped_df<-clipped_df |> mutate(aus.date=date+hours(10))
clipped_df$year <- format(as.Date(clipped_df$aus.date), "%Y")
dea2010<-terra::rast(paste0("../enviro datasets/DEA mangroves/Reprojected", 2010, ".tif"))
pts_sf<-st_as_sf(clipped_df, coords=c("coords.x1", "coords.x2"), crs=crs(clipped_points_df))
pts_sf<-st_transform(pts_sf, crs=4326)
#proj4string(pts_sf) <- CRS(dea2010)
# plot(dea2010)
#
# # Plot sf object on top
# plot(pts_sf, add = TRUE, col = "red", pch = 20)
raster_list<-lapply(2010:2022, function(year) terra::rast(paste0("../enviro datasets/DEA mangroves/Reprojected", year, ".tif")))
pts_sf$deamangrove<-NA
for(i in seq_along(raster_list)){
year <- 2010 + i - 1  # Calculate the corresponding year
cat("doing", year)
matching<-which(pts_sf$year==year)
if(length(matching)>0){
cat("Number of matching points:", length(matching), "\n")
extracted_values <- terra::extract(raster_list[[i]], st_coordinates(pts_sf[matching, ]), method = 'simple')
# Check the dimensions of the extracted values
if (nrow(extracted_values) == length(matching)) {
# Assign extracted values to the deamangrove column in pts_sf
pts_sf$deamangrove[matching] <- extracted_values[, 2]  # Assuming the values are in the second column
} else {
warning("Number of extracted values does not match number of points")
}
}
}
extracted_values
extracted_values[,2]
glimpse(extracted_values)
extracted_values[,1]
pts_sf$deamangrove<-NA
for(i in seq_along(raster_list)){
year <- 2010 + i - 1  # Calculate the corresponding year
cat("doing", year)
matching<-which(pts_sf$year==year)
if(length(matching)>0){
cat("Number of matching points:", length(matching), "\n")
extracted_values <- terra::extract(raster_list[[i]], st_coordinates(pts_sf[matching, ]), method = 'simple')
# Check the dimensions of the extracted values
if (nrow(extracted_values) == length(matching)) {
# Assign extracted values to the deamangrove column in pts_sf
pts_sf$deamangrove[matching] <- extracted_values[, 1]  # Assuming the values are in the second column
} else {
warning("Number of extracted values does not match number of points")
}
}
}
pts_sf
pts_df<-as.data.frame(pts_sf)
glimpse(pts_df)
# Extract the coordinates (longitude and latitude)
coords <- st_coordinates(pts_df$geometry)
# Convert to a data frame
coords_df <- as.data.frame(coords)
# Rename columns to "longitude" and "latitude"
names(coords_df) <- c("lon", "lat")
# Combine with the original dataframe
df_with_coords <- bind_cols(pts_df, coords_df)
pts_df
df_with_coords
pts_df<-df_with_coords%>%select(!geometry)
#Query AIMS thredds server via ExtractEReefsCRW.R and ExtractEReefsbackground.R
# break up dataset for processing
track<-pts_df |> filter(data_type=="track")
write.csv(track, "trackwrasters.csv")
crw<-pts_df |> filter(data_type=="crw")
write.csv(crw, "crwwrasters.csv")
write.csv(crw, "crwwrasters.csv")
background<-clipped |> filter(data_type=="background")
#write.csv(crw, "crwwrasters.csv")
background<- pts_df |> filter(data_type=="background")
write.csv(background, "backgroundwrasters.csv")
table(crw$data_type)
5+1-+13+12+11+11+3+4+2+2+10
5+10+13+12+11+11+3+4+2+2+10
39+34
19+20+12+10+12
5+10+13+12+11+11+3+4+2+2+10
knitr::opts_chunk$set(echo = TRUE)
source("LoadPackages_PA.R")
library(sf)
# combine 12 hr and 24 hr
presence12<-readRDS("20240704ssm.Rds")
presences24<-readRDS("20240704ssm_24h.Rdata")
p12 <- grab(presence12, what = "predicted")
p24 <- grab(presences24, what = "predicted")
presence<-rbind(p12, p24)
#write.csv(presence, "presence_data.csv")
# compile pseudo-absences
# List all files in the directory
subdir<-c("../output.Predicted2024/output.Predicted2024", "../output.Predicted2024/output.Predicted2024_24h")
all_files<-list()
for(i in subdir){
files <- list.files(i, recursive=T, full.names=T)
all_files<-c(all_files, files)
}
all_files<-unlist(all_files)
csv_files <- all_files[grepl("\\.csv$", all_files)]
# Initialize an empty data frames
crw_data <- data.frame()
background_data <- data.frame()
# Loop through each file
for (file in csv_files) {
# Extract the tag from the file name
tag <- gsub(".*sim_|.csv.*", "", file) #start here
cat("doing", file, "n/")
# Check the file name to determine the data type
if (grepl("crw_sim", file)) {
data_type <- "crw"
} else if (grepl("backgroundpts_sim", file)) {
data_type <- "background"
} else {
stop("Invalid file name:", file)
}
# Extract the tag from the file name
tag <- gsub(".*sim_|.csv.*", "", file) #start here
# Read the data from the file
file_data <- read.csv(file)
# Add columns for data type and tag
file_data$data_type <- data_type
file_data$tag <- tag
# Add data to the appropriate data frame
if (data_type == "crw") {
crw_data <- rbind(crw_data, file_data)
} else {
background_data <- rbind(background_data, file_data)
}
}
library(stars)
library(readr)
library(SDLfilter)
library(raster)
library(lubridate)
library(adehabitatLT)
library(momentuHMM)
library(rjags)
library(bsam)
require(tidyverse)
## install aniMotum dev branch (do first time only)
# remotes::install_github("ianjonsen/aniMotum@dev")
require(aniMotum)
library(move)
library(ctmm)
library(adehabitatLT)
require(patchwork)
# Brought csv in to QGIS and visualised individual tracks. Removed 3 possible breeding/courtship in QGIS. When bringing DateTime field into QGIS make sure it comes in as "Date and Time" format to not lose timestamps.
GL<-read.csv("GL_foraging_only.csv")
# # # Retain only foraging- pulled out in QGIS:
Raine<-read.csv(file="Raine_just_foraging.csv", header=T)
SB<-read.csv("SBArgos_foraging_only.csv")
#####################
SB$Deploy.site<-"SB"
Raine$Deploy.site<-"RI"
GL$Deploy.site<-"GL"
# Raine post-breeding tracks already removed
# Shoalwater, removed first 24h
Sh.inds<-unique(SB$id)
SB$DateTime<-as.POSIXct(SB$DateTime, format='%Y/%m/%d %H:%M:%S')
SB <-SB%>%
arrange(id, DateTime) %>%
group_by(id) %>%
filter(!(DateTime < min(DateTime) + hours(24)))
# Gladstone
GL$DateTime<-as.POSIXct(GL$DateTime, format='%Y/%m/%d %H:%M:%S', tz="GMT")
GL <-GL%>%
arrange(id, DateTime) %>%
group_by(id) %>%
filter(!(DateTime < min(DateTime) + hours(24))) #remove first 24 hours
glimpse(GL)
#Calculate average duration per turtle
#read.csv("20240704filteredFGPS&ARGOS.csv")
all%>%filter(data_type==1)%>%
arrange(as.Date(date.x))%>%
group_by(Primary.tag,PTT)%>%
summarise(first=first(as.Date(date.x)), last=last(as.Date(date.x)))%>%
mutate(duration=difftime(last,first,units='days'))%>%
View()
#Calculate average duration per turtle
read.csv("20240704filteredFGPS&ARGOS.csv")
#Calculate average duration per turtle
all<-read.csv("20240704filteredFGPS&ARGOS.csv")
#Calculate average duration per turtle
#all<-read.csv("20240704filteredFGPS&ARGOS.csv")
glimpse(all)
all%>%
arrange(as.Date(DateTime))%>%
group_by(id)%>%
summarise(first=first(as.Date(DateTime)), last=last(as.Date(DateTime)))%>%
mutate(duration=difftime(last,first,units='days'))%>%
View()
all%>%
arrange(as.Date(DateTime))%>%
group_by(id)%>%
summarise(first=first(as.Date(DateTime)), last=last(as.Date(DateTime)))%>%
mutate(duration=difftime(last,first,units='days'))%>%
View()%>%
summarise(mean.duration=mean(duration))
all%>%
arrange(as.Date(DateTime))%>%
group_by(id)%>%
summarise(first=first(as.Date(DateTime)), last=last(as.Date(DateTime)))%>%
mutate(duration=difftime(last,first,units='days'))%>%
View()%>%
ungroup%>%
summarise(mean.duration=mean(duration))
all%>%
arrange(as.Date(DateTime))%>%
group_by(id)%>%
summarise(first=first(as.Date(DateTime)), last=last(as.Date(DateTime)))%>%
mutate(duration=difftime(last,first,units='days'))%>%
View()%>%
ungroup()%>%
summarise(mean.duration=mean(duration))
ungroup()%>%
summarise(mean.duration=mean(duration))
a%>%
summarise(mean.duration=mean(duration))
a<-all%>%
arrange(as.Date(DateTime))%>%
group_by(id)%>%
summarise(first=first(as.Date(DateTime)), last=last(as.Date(DateTime)))%>%
mutate(duration=difftime(last,first,units='days'))%>%
View()
a%>%
summarise(mean.duration=mean(duration))
mean(a$duration)
glimpse(a)
a<-all%>%
arrange(as.Date(DateTime))%>%
group_by(id)%>%
summarise(first=first(as.Date(DateTime)), last=last(as.Date(DateTime)))%>%
mutate(duration=difftime(last,first,units='days'))#%>%
glimpse(a)
mean(a$duration)
knitr::opts_chunk$set(echo = TRUE)
all<-read("PBC.csv")
all<-read.csv("PBC.csv")
table(PBC$id)
table(all$id)
85-43
42/85
1/9
a<-all%>%
arrange(as.Date(DateTime))%>%
group_by(id)%>%
summarise(first=first(as.Date(DateTime)), last=last(as.Date(DateTime)))%>%
mutate(duration=difftime(last,first,units='days'))#%>%
a<-all%>%
arrange(as.Date(DateTime))%>%
group_by(id)%>%
summarise(first=first(as.Date(DateTime)), last=last(as.Date(DateTime)))%>%
mutate(duration=difftime(last,first,units='days'))%>%
View()
library(dplyr)
a<-all%>%
arrange(as.Date(DateTime))%>%
group_by(id)%>%
summarise(first=first(as.Date(DateTime)), last=last(as.Date(DateTime)))%>%
mutate(duration=difftime(last,first,units='days'))%>%
View()
mean(a$duration)
library(lubridate)
a<-all%>%
arrange(as.Date(DateTime))%>%
group_by(id)%>%
summarise(first=first(as.Date(DateTime)), last=last(as.Date(DateTime)))%>%
mutate(duration=difftime(last,first,units='days'))%>%
View()
glimpse(all)
#Calculate average duration per turtle
all<-read.csv("20240704filteredFGPS&ARGOS.csv")
glimpse(all)
a<-all%>%
arrange(as.Date(DateTime))%>%
group_by(id)%>%
summarise(first=first(as.Date(DateTime)), last=last(as.Date(DateTime)))%>%
mutate(duration=difftime(last,first,units='days'))%>%
View()
mean(a$duration)
knitr::opts_chunk$set(echo = TRUE)
source("PA-paper/LoadPackages_PA.R")
knitr::opts_chunk$set(echo = TRUE)
source("LoadPackages_PA.R")
library(sf)
COMMUNITY<-terra::vect("../enviro datasets/NESP predicted distribution of seagrass communities/Shapefiles/GBR_NESP-TWQ-5.4_JCU_Seagrass-communities_20201203.shp")%>%
st_as_sf()
COMMUNITY<-terra::vect("../enviro datasets/NESP predicted distribution of seagrass communities/Shapefiles/GBR_NESP-TWQ-5.4_JCU_Seagrass-communities_20201203.shp")%>%
st_as_sf()
#clipped_points_df<-readRDS("20240711appendinprogress.Rds"
COMMUNITY<-terra::vect("../enviro datasets/NESP predicted distribution of seagrass communities/Shapefiles/GBR_NESP-TWQ-5.4_JCU_Seagrass-communities_20201203.shp")
# clipped_points_df<-readRDS("20240711appendinprogress.Rds")
# set.seed(123)
# subsetindices<-sample(1:nrow(clipped_points_df), 5000)
# subset<-clipped_points_df[subsetindices,]
# subsetvect<-terra::vect(subset)
bathy<-terra::rast("../enviro datasets/rasters for grid predictions/bathy.tif")
crs(COMMUNITY)
crs(bathy)
extent<-extent(bathy)
extent<-ext(bathy)
extent<-terra::ext(bathy)
crs<-crs(bathy)
COMMUNITY<-project(COMMUNITY, crs)
extent<-terra::ext(bathy)
crs<-crs(bathy)
COMMUNITY<-terra::project(COMMUNITY, crs)
resolution=30
COMMUNITY$COMMUNITY<-as.factor(COMMUNITY$COMMUNITY)
y=terra::rast(COMMUNITY, resolution=30, extent=extent, crs=crs(bathy))
seagrassCom<-terra::rasterize(COMMUNITY, y, field='COMMUNITY')
seagrasscrop <- crop(seagrassCom, extent(extent))
ra<-aggregate(seagrasscrop, fact=2)
ra<-aggregate(seagrassCom, fact=2)
image(seagrassCom)
str(seagrassCom)
clipped_points_vect<-terra::vect(clipped_points_df)
clipped_points_df<-readRDS("20240711appendinprogress.Rds")
clipped_points_vect<-terra::vect(clipped_points_df)
COMMUNITY1<-terra::extract(seagrassCom, clipped_points_vect)
table(COMMUNITY1)
str(COMMUNITY1)
table(COMMUNITY1$COMMUNITY)
clipped_points_vect$COMMUNITY<-COMMUNITY1[,2]
clipped_points<-st_as_sf(clipped_points_vect)
clipped_points_df<-as(clipped_points, "Spatial")
saveRDS(clipped_points_df, file="20240806appendinprogress.Rds")
raster::writeRaster(seagrassCom, "seagrassCom.asc")
knitr::opts_chunk$set(echo = TRUE)
source("LoadPackages_PA.R")
library(sf)
knitr::opts_chunk$set(echo = TRUE)
hyd4<-read.csv("eReefsAppendOutputs/hydro_4dimscrw.csv")
hyd4<-read.csv("eReefsAppendOutputs/hydro_4dimscrw.csv")
hyd3<-read.csv("eReefsAppendOutputs/hydro_3dimscrw.csv")
hyd3<-read.csv("eReefsAppendOutputs/hydro_3dimscrw.csv")
hyd3<-read.csv("eReefsAppendOutputs/hydro_3dimscrw1.csv")
hyd3<-read.csv("eReefsAppendOutputs/hydro_3dimscrw1.csv")
bgc4<-read.csv("eReefsAppendOutputs/bgc_4dimscrw.Rds")
bgc3<-read.csv("eReefsAppendOutputs/bgc_3dimscrw.Rds")
track<-read.csv("bgc_3dimstrack.csv")
track<-read.csv("eReefsAppendOutputs/bgc_3dimstrack.csv")
track<-read.csv("eReefsAppendOutputs/bgc_3dimstrack.csv")
background<-read.csv("eReefsAppendOutputs/bgc_3dimsbackground.csv")
community<-readRDS("20240806appendinprogress.Rds")
1779427+16482+252567
bgc4%>%filter(aus.date=="2018-12-01")%>%glimpse()
glimpse(bgc4)
bgc4<-read.csv("eReefsAppendOutputs/bgc_4dimscrw.csv") # these didn't work
bgc3<-readRDS("eReefsAppendOutputs/bgc_3dimscrw.Rds") # these didn't work
bgc3%>%filter(aus.date=="2018-12-01")%>%glimpse()
bgc3%>%filter(aus.date=="2019-03-01")%>%glimpse()
bgc3%>%filter(aus.date=="2019-02-01")%>%glimpse()
hyd3%>%filter(aus.date=="2019-02-01")%>%glimpse()
hyd4%>%filter(aus.date=="2019-02-01")%>%glimpse()
# Combine the CRW files
# # arrange dfs by index
hyd4test<-hyd4%>%arrange(X.3)
# # add in hyd3dims vars
#
hyd3vars<-hyd3%>%arrange(X.3)
hydtest<-cbind(hyd4test, hyd3vars[, c("mean_wspeed")])
# add in bgc vars
bgc4vars<-bgc4%>%arrange(X.3)
glimpse(bgc3)
hyd4<-read.csv("eReefsAppendOutputs/hydro_4dimscrw.csv")
hyd3<-read.csv("eReefsAppendOutputs/hydro_3dimscrw1.csv")
# bgc4<-read.csv("eReefsAppendOutputs/bgc_4dimscrw.csv")
bgc3<-readRDS("eReefsAppendOutputs/bgc_3dimscrw.Rds")
track<-read.csv("eReefsAppendOutputs/bgc_3dimstrack.csv")
background<-read.csv("eReefsAppendOutputs/bgc_3dimsbackground.csv")
community<-readRDS("20240806appendinprogress.Rds")
# Combine the CRW files
# # arrange dfs by index
hyd4test<-hyd4%>%arrange(X)
# # add in hyd3dims vars
#
hyd3vars<-hyd3%>%arrange(X)
hydtest<-cbind(hyd4test, hyd3vars[, c("mean_wspeed")])
# add in bgc vars
bgc4vars<-bgc4%>%arrange(X)
bgc3vars<-bgc3%>%arrange(X)
bgc4test<-cbind(hydtest, bgc4vars[, c("ZooL_N", "EFI")])
bgc3test<-cbind(bgc4test, bgc3vars[, c("Secchi")])
bgc3test<-bgc3test%>%rename("mean_wspeed"=`hyd3vars[, c("mean_wspeed")]`,
"Secchi"=`bgc3vars[, c("Secchi")]`)
glimpse(bgc3test)
bgc4%>%filter(aus.date=="2013-08-04")%>%glimpse()
bgc3%>%filter(aus.date=="2013-08-04")%>%glimpse()
sum(is.na(bgc3test$Secchi))
sum(is.na(bgc3test$EFI))
sum(is.na(bgc3test$temp))
glimpse(track)
glimpse(background)
AppendedAll<- rbind(bgc3test, track, background)
common_cols=intersect(colnames(bgc3test), colnames(track), colnames(background))
common_cols=intersect(colnames(bgc3test), colnames(track))
common_cols
AppendedAll<- rbind(bgc3test[,common_cols], track[,common_cols], background[,common_cols])
glimpse(community)
# add in community
clipped_df<-as.data.frame(community)
glimpse(community)
clipped_df<-clipped_df |> mutate(aus.date=date+hours(10))
clipped_df$year <- format(as.Date(clipped_df$aus.date), "%Y")
clipped_df$year <- format(as.Date(clipped_df$aus.date), "%Y")
pts_sf<-st_as_sf(clipped_df, coords=c("coords.x1", "coords.x2"), crs=crs(clipped_points_df))
crs(community)
pts_sf<-st_as_sf(clipped_df, coords=c("coords.x1", "coords.x2"), crs=crs(community))
pts_sf<-st_transform(pts_sf, crs=4326)
pts_df<-as.data.frame(pts_sf)
# Extract the coordinates (longitude and latitude)
coords <- st_coordinates(pts_df$geometry)
# Convert to a data frame
coords_df <- as.data.frame(coords)
# Rename columns to "longitude" and "latitude"
names(coords_df) <- c("lon", "lat")
# Combine with the original dataframe
df_with_coords <- bind_cols(pts_df, coords_df)
pts_df<-df_with_coords%>%select(!geometry)
glimpse(pts_df)
?left_join
AppendedAll1<-AppendAll%>%left_join(pts_df, by=c(id, date, data_type, iteration, builtfeatures, geohab, geomorph, aus.date, year, lon, lat))
AppendedAll1<-AppendedAll%>%left_join(pts_df, by=c(id, date, data_type, iteration, builtfeatures, geohab, geomorph, aus.date, year, lon, lat))
glimpse(AppendAll)
glimpse(AppendedAll)
AppendedAll1<-AppendedAll%>%left_join(pts_df, by=c("id", "date", "data_type", "iteration", "builtfeatures", "geohab", "geomorph", "aus.date", "year", "lon", "lat"))
#
# # Convert to a data frame
# coords_df <- as.data.frame(coords)
#
# # Rename columns to "longitude" and "latitude"
# names(coords_df) <- c("lon", "lat")
#
# # Combine with the original dataframe
# df_with_coords <- bind_cols(pts_df, coords_df)
# pts_df<-df_with_coords%>%select(!geometry)
pts_sf$date<-as.character(pts_st$date)
#
# # Convert to a data frame
# coords_df <- as.data.frame(coords)
#
# # Rename columns to "longitude" and "latitude"
# names(coords_df) <- c("lon", "lat")
#
# # Combine with the original dataframe
# df_with_coords <- bind_cols(pts_df, coords_df)
# pts_df<-df_with_coords%>%select(!geometry)
pts_sf$date<-as.character(pts_sf$date)
glimpse(pts_sf)
AppendedAll1<-AppendedAll%>%left_join(pts_df, by=c("id", "date", "data_type", "iteration", "builtfeatures", "geohab", "geomorph", "aus.date", "year", "lon", "lat"))
pts_sf$aus.date<-as.character(pts_sf$aus.date)
#
# # Convert to a data frame
# coords_df <- as.data.frame(coords)
#
# # Rename columns to "longitude" and "latitude"
# names(coords_df) <- c("lon", "lat")
#
# # Combine with the original dataframe
# df_with_coords <- bind_cols(pts_df, coords_df)
# pts_df<-df_with_coords%>%select(!geometry)
pts_df$date<-as.character(pts_df$date)
glimpse(pts_df)
pts_df$aus.date<-as.character(pts_sf$aus.date)
AppendedAll1<-AppendedAll%>%left_join(pts_df, by=c("id", "date", "data_type", "iteration", "builtfeatures", "geohab", "geomorph", "aus.date", "year", "lon", "lat"))
pts_df$aus.date<-as.character(pts_df$aus.date)
pts_df$year<-as.integer(pts_df$year)
glimpse(pts_df)
AppendedAll1<-AppendedAll%>%left_join(pts_df, by=c("id", "date", "data_type", "iteration", "builtfeatures", "geohab", "geomorph", "aus.date", "year", "lon", "lat"))
glimpse(AppendedAll1)
table(AppendedAll1$COMMUNITY)
# # save this
write.csv(AppendedAll, "20240806AppendedAll.csv")
#remove spatial/temporal where there is too much missing predictor data (eReefs BGC goes until 2019 only)
AppendedAll%>%arrange(date)%>%visdat::vis_miss()
?slice_sample
#remove spatial/temporal where there is too much missing predictor data (eReefs BGC goes until 2019 only)
AppendedAll%>%arrange(date)%>%slice_sample(n=500000)%>%visdat::vis_miss()
#remove spatial/temporal where there is too much missing predictor data (eReefs BGC goes until 2019 only)
AppendedAll%>%arrange(date)%>%slice_sample(n=100000)%>%visdat::vis_miss()
#remove spatial/temporal where there is too much missing predictor data (eReefs BGC goes until 2019 only)
AppendedAll%>%arrange(date)%>%slice_sample(n=50000)%>%visdat::vis_miss()
#remove spatial/temporal where there is too much missing predictor data (eReefs BGC goes until 2019 only)
AppendedAll%>%arrange(date)%>%slice_sample(n=50000)%>%visdat::vis_miss(warn_large_data = F)
bgc4<-readRDS("eReefsAppendOutputs/bgc_4dimscrw.Rds")
glimpse(bgc4)
sum(is.na(bgc4$EFI))
sum(is.na(bgc4$ZooL_N))
sum(bgc4$ZooL_N=="")
glimpse(hyd4)
200/24
bgc4%>%filter(aus.date=="2018-12-01")%>%glimpse()
bgc4%>%filter(aus.date=="2016-12-01")%>%glimpse()
bgc4%>%filter(aus.date=="2017-12-01")%>%glimpse()
bgc4%>%filter(aus.date=="2017-01-01")%>%glimpse()
bgc4%>%filter(aus.date=="2017-03-01")%>%glimpse()
bgc4%>%filter(aus.date=="2018-03-01")%>%glimpse()
bgc4%>%filter(aus.date=="2018-06-01")%>%glimpse()
bgc4%>%filter(aus.date=="2018-09-01")%>%glimpse()
bgc4%>%filter(aus.date=="2018-10-01")%>%glimpse()
bgc4%>%filter(aus.date=="2018-11-01")%>%glimpse()
bgc4%>%filter(aus.date=="2018-12-01")%>%glimpse()
bgc4%>%filter(aus.date=="2019-01-01")%>%glimpse()
bgc4%>%filter(aus.date=="2019-02-01")%>%glimpse()
bgc4%>%filter(aus.date=="2019-03-01")%>%glimpse()
25/3
38491*45748
